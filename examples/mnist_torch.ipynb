{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from fastai.vision.all import URLs, untar_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/home/akash/.fastai/data/mnist_png/training'),Path('/home/akash/.fastai/data/mnist_png/testing')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path).ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class DataLoaders:\n",
    "    BATCHSIZE = 250 # Default batch size\n",
    "    SHUFFLE = True\n",
    "    def __init__(\n",
    "            self, path, train: str, valid:str,\n",
    "            batch_size:int = BATCHSIZE,\n",
    "            shuffle: bool = SHUFFLE,\n",
    "        ) -> None:\n",
    "        self.path = path\n",
    "        self.train_path = os.path.join(path, train)\n",
    "        self.valid_path = os.path.join(path, valid)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.X_train, self.Y_train = self.load_from_folder(directory=self.train_path)\n",
    "        self.X_valid, self.Y_valid = self.load_from_folder(directory=self.valid_path)\n",
    "\n",
    "    def load_from_folder(self, directory):\n",
    "        from PIL import Image\n",
    "        classes = os.listdir(path=directory)\n",
    "        X_data, Y_data = [], []\n",
    "\n",
    "        for idx, cls_name in enumerate(classes):\n",
    "            cls_path = os.path.join(directory, cls_name) # mnist/training/5\n",
    "            imgs = os.listdir(cls_path) # number of images\n",
    "            for img_name in imgs:\n",
    "                img_path = os.path.join(cls_path, img_name)\n",
    "                with Image.open(img_path) as img:\n",
    "                    img = img.resize((28,28))\n",
    "                    img = np.array(img, dtype=np.uint8)\n",
    "                    X_data.append(img) # add image\n",
    "                    Y_data.append(idx) # add label\n",
    "        X_data, Y_data = np.array(X_data), np.array(Y_data)\n",
    "        if self.shuffle:\n",
    "            indices = np.arange(len(X_data))\n",
    "            np.random.shuffle(indices)\n",
    "            X_data, Y_data = X_data[indices], Y_data[indices]\n",
    "        return X_data, Y_data\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns total number of data in single batch.\"\"\"\n",
    "        if not self.X_train: raise(\"Data not loaded yet\")\n",
    "        return len(self.X_train) // self.batch_size\n",
    "\n",
    "    def __str__(self):\n",
    "        train_data = list(zip(self.x_train, self.y_train))\n",
    "        return f\"{train_data}\"\n",
    "\n",
    "    def get_validation_data(self):\n",
    "        if not self.x_val and not self.y_val: return None\n",
    "        return list(zip(self.x_val, self.y_val))\n",
    "\n",
    "\n",
    "dls = DataLoaders(path=path, train='training', valid='testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47040000, (60000, 784), 784)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dls.X_train.reshape((-1, 28*28))\n",
    "x.size, x.shape, 28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_tinyNet(i, o):\n",
    "    weights = np.random.uniform(-1., 1., size=(i,o)) / np.sqrt(i*o)\n",
    "    bias = np.zeros((o,))\n",
    "    return weights, bias\n",
    "\n",
    "def forward_pass(input_data, weight)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have X_train, Y_train & X_valid, Y_valid\n",
    "\n",
    "Flatten those and pass into a layer -- dont know how we create a layer\n",
    "\n",
    "it should give an output (logits)\n",
    "\n",
    "logits -> softmax -> predictions\n",
    "\n",
    "    1. predictions -> cross_entropy_loss -> loss\n",
    "    2. calculate gradient\n",
    "\n",
    "use gradient to step\n",
    "\n",
    "repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
