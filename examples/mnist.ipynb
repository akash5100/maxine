{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/home/akzsh/.fastai/data/mnist_png/training'),Path('/home/akzsh/.fastai/data/mnist_png/testing')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from fastai.vision.all import URLs, untar_data\n",
    "\n",
    "path = untar_data(URLs.MNIST)\n",
    "(path).ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes: 100%|██████████| 10/10 [00:09<00:00,  1.08class/s]\n",
      "Classes: 100%|██████████| 10/10 [00:01<00:00,  6.72class/s]\n"
     ]
    }
   ],
   "source": [
    "class DataLoaders:\n",
    "    def __init__(\n",
    "            self, path, train: str, valid:str,\n",
    "            batch_size:int = 64,\n",
    "            shuffle: bool = True,\n",
    "        ) -> None:\n",
    "        self.path = path\n",
    "        self.train_path = os.path.join(path, train)\n",
    "        self.valid_path = os.path.join(path, valid)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.X_train, self.Y_train = self.load_from_folder(directory=self.train_path)\n",
    "        self.X_valid, self.Y_valid = self.load_from_folder(directory=self.valid_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns total number of data in single batch.\"\"\"\n",
    "        if not self.X_train: raise(\"Data not loaded yet\")\n",
    "        return len(self.X_train) // self.batch_size\n",
    "\n",
    "    def __str__(self):\n",
    "        train_data = list(zip(self.x_train, self.y_train))\n",
    "        return f\"{train_data}\"\n",
    "\n",
    "    def load_from_folder(self, directory):\n",
    "        from PIL import Image\n",
    "        classes = os.listdir(path=directory)\n",
    "        X_data, Y_data = [], []\n",
    "\n",
    "        with tqdm(classes, desc='Classes', unit='class') as pbar_classes:\n",
    "            for idx, cls_name in enumerate(pbar_classes):\n",
    "                cls_path = os.path.join(directory, cls_name) # mnist/training/5\n",
    "                imgs = os.listdir(cls_path) # number of images\n",
    "                for img_name in imgs:\n",
    "                    img_path = os.path.join(cls_path, img_name)\n",
    "                    with Image.open(img_path) as img:\n",
    "                        img = img.resize((28,28))\n",
    "                        img = np.array(img, dtype=np.uint8)\n",
    "                        X_data.append(img) # add image\n",
    "                        Y_data.append(idx) # add label\n",
    "            pbar_classes.update(1)\n",
    "        X_data, Y_data = np.array(X_data), np.array(Y_data)\n",
    "        if self.shuffle:\n",
    "            indices = np.arange(len(X_data))\n",
    "            np.random.shuffle(indices)\n",
    "            X_data, Y_data = X_data[indices], Y_data[indices]\n",
    "        return X_data, Y_data\n",
    "\n",
    "    def get_validation_data(self):\n",
    "        if not self.x_val and not self.y_val: return None\n",
    "        return list(zip(self.x_val, self.y_val))\n",
    "\n",
    "\n",
    "dls = DataLoaders(path=path, train='training', valid='testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "def mse(preds, targs): return ((preds-targs)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func to init weights\n",
    "def init_params(size): return torch.randn(size).float().requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]),\n",
       " torch.Size([60000]),\n",
       " torch.Size([10000, 784]),\n",
       " torch.Size([10000]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(dls.X_train).float()/255\n",
    "y = torch.tensor(dls.Y_train).long()\n",
    "\n",
    "x_valid = torch.tensor(dls.X_valid).float()/255\n",
    "y_valid = torch.tensor(dls.Y_valid).long()\n",
    "\n",
    "x = x.view(x.size(0), -1)\n",
    "x_valid = x_valid.view(x_valid.size(0), -1)\n",
    "\n",
    "x.shape, y.shape, x_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 10]), torch.Size([60000, 10]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = init_params((28*28, 10))\n",
    "b1 = init_params((60000,10))\n",
    "\n",
    "w1.shape,b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(xb): return xb@w1 + b1\n",
    "loss_func = torch.nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 10])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = linear(x)\n",
    "preds = F.sigmoid(preds)\n",
    "preds = F.softmax(preds, dim=-1)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0963)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (torch.argmax(preds, dim=-1) == y).float().mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_func(preds, y.long())\n",
    "loss = loss.mean()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6894,  1.2834,  0.0073,  ..., -1.3896, -0.9225, -1.4367],\n",
       "        [-0.2047,  1.5760,  0.5729,  ..., -1.1914, -0.0602, -1.3356],\n",
       "        [-0.8234, -0.1500, -0.2901,  ...,  0.5081, -0.2496,  1.3350],\n",
       "        ...,\n",
       "        [ 0.5122, -0.1415, -0.5266,  ..., -0.5527, -0.2687,  1.1023],\n",
       "        [-0.4032, -0.7966, -0.4806,  ...,  0.5505,  1.0336,  0.3005],\n",
       "        [-0.8680,  1.1277, -1.4253,  ...,  0.2940, -0.4425, -0.3616]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e-2\n",
    "w1.data += w1.grad.data * lr\n",
    "b1.data += b1.grad.data * lr\n",
    "w1.grad.zero_(),b1.grad.zero_()\n",
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maxine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
